{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d420a8",
   "metadata": {},
   "source": [
    "Notebook này là source code dùng để thu thập tất cả link của các loài động vật trên trang https://animalia.bio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fa8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cài đặt selenium, chrome, chromedriver\n",
    "#!pip install selenium\n",
    "#!apt-get update \n",
    "#!apt install chromium-chromedriver\n",
    "#!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "#Cài đặt beautifulsoup để crawl dữ liệu, vì beautifulsoup sẽ nhanh hơn selenium\n",
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349bcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8cc305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Khởi tạo driver\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b2cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url của trang cần lấy dữ liệu\n",
    "urls = {   \n",
    "        'https://animalia.bio/mammals': 151 ,\n",
    "        'https://animalia.bio/reptiles': 107, \n",
    "        'https://animalia.bio/amphibia' : 82,\n",
    "        'https://animalia.bio/mollusk': 117,\n",
    "        'https://animalia.bio/birds' : 247\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1bcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm lấy dữ liệu của 1 trang rồi lưu nó xuống file html\n",
    "def get_url(url, num_pages):\n",
    "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    driver.get(url)\n",
    "    print(driver.current_url)\n",
    "    page = 1\n",
    "    while page < num_pages:\n",
    "      try:\n",
    "        driver.find_element(\"xpath\", '/html/body/div[3]/div[2]/div/div[5]/div[3]/div[1]/span').click()\n",
    "        page += 1\n",
    "        print(page, num_pages)\n",
    "      except:\n",
    "        pass\n",
    "    animals_class = url[21:]\n",
    "    name = animals_class + '.html'\n",
    "    with open(name, \"w\") as f:\n",
    "        f.write(driver.page_source)     \n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad10a2e",
   "metadata": {},
   "source": [
    "Cơ chế của website này là click vào button \"LOAD MORE\" thì sẽ cập nhật thêm dữ liệu của trang mới vào và dữ liệu trang cũ vẫn còn đó. Ví dụ trang 1 là dữ liệu của động vật có số thứ tự từ thứ 1-42 thì sau khi click vào thì dữ liệu trang 1 sẽ thành 1-84. Như vậy, ta sẽ click vào button \"LOAD MORE\" cho đến khi load hết tất cả dữ liệu . Mặc dù khi bấm vào button \"LOAD MORE\" thì url của trang có đổi nhưng nhóm vẫn không hiểu vì sao nếu nhập tay url vào thì nó tự reset về trang 1. Vì vậy nhóm phải dùng selenium để click vào button cho tới trang cuối cùng.\n",
    "\n",
    "Test ở link :https://animalia.bio/mammals?page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6060ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chạy tất cả các link, mỗi link xuất ra file csv\n",
    "for url, num_pages in urls.items():\n",
    "    get_url(url, num_pages)\n",
    "    animals_class = url[21:]\n",
    "    name = animals_class + '.html'\n",
    "    #Dùng beautifulsoup để tìm tất cả các thẻ a\n",
    "    with open(name) as fp:\n",
    "        soup = BeautifulSoup(fp, \"html.parser\")\n",
    "    animals_urls = soup.find_all(\"a\", {\"class\": \"animals-invert__item\"}) #Tìm tất cả các link của thú rồi lưu vào biến\n",
    "\n",
    "    animals_urls = [a['href'][:-11] for a in animals_urls] #Lấy link của từng thú, bỏ phần \"?category=1\"\n",
    "    animals_urls_df = pd.DataFrame(data = animals_urls, columns = [\"url\"])\n",
    "    animals_urls_df.to_csv(f'{animals_class}.csv') #Xuất kết quả ra file csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a415f",
   "metadata": {},
   "source": [
    "Ở phần tìm các thẻ chứa link rồi lưu xuống file csv thì nhóm chọn BeautifulSoup vì nó đơn giản và nhanh hơn Selenium nhiều."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6585d2",
   "metadata": {},
   "source": [
    "Bây giờ, kết quả đã lưu thành 5 file csv, đó là file \"mammals.csv\", \"reptiles.csv\", \"amphibia.csv\", \"mollusk.csv\" và \"birds.csv\". Cần tổng hợp lại thành 1 file duy nhất là \"animals_urls.csv\" để tiện hơn cho việc thu thập dữ liệu từng động vật."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54fd06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_csv = [\"mammals.csv\", \"reptiles.csv\", \"amphibia.csv\", \"mollusk.csv\", \"birds.csv\"]\n",
    "animals = pd.Series(dtype = object)\n",
    "for csv in list_csv:\n",
    "    df = pd.read_csv(csv)\n",
    "    animals = pd.concat([animals, df['url']], ignore_index=True)\n",
    "df_animals = pd.DataFrame(animals, columns = [\"url\"])\n",
    "df_animals.to_csv('animals_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674251c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
